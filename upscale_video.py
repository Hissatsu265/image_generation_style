import os
import torch
from PIL import Image
import sys
import cv2
import subprocess
import shutil
import glob
import numpy as np
# sys.path.append('/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN')
current_dir = os.path.dirname(os.path.abspath(__file__))
realesrgan_path = os.path.join(current_dir, 'RealESRGAN')
sys.path.append(realesrgan_path)
from RealESRGAN import RealESRGAN
import time

def blend_images(original, upscaled, blend_ratio=0.2):
    """Tr·ªôn ·∫£nh g·ªëc v·ªõi ·∫£nh upscaled ƒë·ªÉ gi·∫£m hi·ªáu ·ª©ng ho·∫°t h√¨nh"""
    # Resize ·∫£nh g·ªëc l√™n c√πng k√≠ch th∆∞·ªõc v·ªõi ·∫£nh upscaled
    original_resized = original.resize(upscaled.size, Image.LANCZOS)

    # Convert sang numpy ƒë·ªÉ x·ª≠ l√Ω
    orig_np = np.array(original_resized, dtype=np.float32)
    upsc_np = np.array(upscaled, dtype=np.float32)

    # Tr·ªôn theo t·ª∑ l·ªá
    blended = (1 - blend_ratio) * upsc_np + blend_ratio * orig_np
    blended = np.clip(blended, 0, 255).astype(np.uint8)

    return Image.fromarray(blended)

def apply_sharpening(image, strength=0.3):
    """√Åp d·ª•ng sharpening nh·∫π ƒë·ªÉ tƒÉng ƒë·ªô s·∫Øc n√©t t·ª± nhi√™n"""
    img_np = np.array(image)

    # Gaussian blur
    blurred = cv2.GaussianBlur(img_np, (3, 3), 1.0)

    # Unsharp masking
    sharpened = cv2.addWeighted(img_np, 1 + strength, blurred, -strength, 0)

    return Image.fromarray(np.clip(sharpened, 0, 255).astype(np.uint8))

def upscale_image_enhanced(input_path: str, output_path: str = "results", scale: int = 4,
                          model_type: str = "realesr-general", blend_ratio: float = 0.0,
                          sharpen: bool = False):
    """Upscale m·ªôt ·∫£nh ƒë∆°n l·∫ª v·ªõi c√°c t√πy ch·ªçn c·∫£i ti·∫øn"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = RealESRGAN(device, scale=scale)

    # Ch·ªçn model ph√π h·ª£p
    if model_type == "realesr-general":
        model_path = f'/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN/weights/realesr-general-x4v3.pth'
    else:
        model_path = f'/workspace/multitalk_verquant/RealESRGAN/RealESRGAN/weights/RealESRGAN_x2.pth'

    model.load_weights(model_path, download=False)

    os.makedirs(output_path, exist_ok=True)
    image_name = os.path.basename(input_path)
    print(f"\nüöÄ ƒêang x·ª≠ l√Ω: {image_name}")
    print(f"üé® Model: {model_type}")
    print(f"üîÄ Blend ratio: {blend_ratio}")
    print(f"‚ú® Sharpening: {'C√≥' if sharpen else 'Kh√¥ng'}")

    original_image = Image.open(input_path).convert('RGB')

    start = time.time()
    sr_image = model.predict(original_image)

    if blend_ratio > 0:
        sr_image = blend_images(original_image, sr_image, blend_ratio)
        print(f"üîÄ ƒê√£ √°p d·ª•ng blending v·ªõi t·ª∑ l·ªá {blend_ratio}")

    if sharpen:
        sr_image = apply_sharpening(sr_image)
        print(f"‚ú® ƒê√£ √°p d·ª•ng sharpening")

    elapsed = time.time() - start
    save_path = os.path.join(output_path, f"upscaled_{image_name}")
    sr_image.save(save_path)

    print(f"‚úÖ ƒê√£ upscale xong ·∫£nh: {image_name}")
    print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {elapsed:.2f} gi√¢y")
    print(f"üíæ ƒê√£ l∆∞u ·∫£nh t·∫°i: {save_path}")

    return save_path

def get_video_info(video_path: str):
    """L·∫•y th√¥ng tin video (fps, duration, etc.)"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    return {
        'fps': fps,
        'frame_count': frame_count,
        'duration': duration,
        'width': width,
        'height': height
    }

def extract_frames(video_path: str, output_dir: str):
    """T√°ch video th√†nh c√°c frame b·∫±ng ffmpeg"""
    os.makedirs(output_dir, exist_ok=True)

    cmd = [
        'ffmpeg', '-i', video_path,
        '-q:v', '1',
        '-pix_fmt', 'rgb24',
        os.path.join(output_dir, 'frame_%06d.png'),
        '-y'
    ]

    print(f"üé¨ ƒêang t√°ch video th√†nh frames...")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print(f"‚ùå L·ªói khi t√°ch frames: {result.stderr}")
        return False

    frame_files = glob.glob(os.path.join(output_dir, 'frame_*.png'))
    print(f"‚úÖ ƒê√£ t√°ch ƒë∆∞·ª£c {len(frame_files)} frames")
    return True

def upscale_frames_enhanced(frames_dir: str, output_dir: str, scale: int = 4,
                           model_type: str = "realesr-general", blend_ratio: float = 0.0,
                           sharpen: bool = False):
    """Upscale t·∫•t c·∫£ c√°c frame v·ªõi c√°c t√πy ch·ªçn c·∫£i ti·∫øn"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è S·ª≠ d·ª•ng device: {device}")
    print(f"üé® Model: {model_type}")
    print(f"üîÄ Blend ratio: {blend_ratio}")
    print(f"‚ú® Sharpening: {'C√≥' if sharpen else 'Kh√¥ng'}")

    model = RealESRGAN(device, scale=scale)

    if model_type == "realesr-general":
        model_path = f'/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN/weights/realesr-general-x4v3.pth'
    else:
        model_path = f'/workspace/multitalk_verquant/RealESRGAN/RealESRGAN/weights/RealESRGAN_x2.pth'

    model.load_weights(model_path, download=False)

    os.makedirs(output_dir, exist_ok=True)

    frame_files = sorted(glob.glob(os.path.join(frames_dir, 'frame_*.png')))
    total_frames = len(frame_files)

    if total_frames == 0:
        print("‚ùå Kh√¥ng t√¨m th·∫•y frame n√†o ƒë·ªÉ x·ª≠ l√Ω!")
        return False

    print(f"üöÄ B·∫Øt ƒë·∫ßu upscale {total_frames} frames...")
    start_time = time.time()

    for i, frame_path in enumerate(frame_files, 1):
        frame_start = time.time()

        original_image = Image.open(frame_path).convert('RGB')
        sr_image = model.predict(original_image)

        # √Åp d·ª•ng c√°c k·ªπ thu·∫≠t c·∫£i ti·∫øn
        if blend_ratio > 0:
            sr_image = blend_images(original_image, sr_image, blend_ratio)

        if sharpen:
            sr_image = apply_sharpening(sr_image)

        frame_name = os.path.basename(frame_path)
        output_path = os.path.join(output_dir, frame_name)
        sr_image.save(output_path)

        frame_elapsed = time.time() - frame_start
        total_elapsed = time.time() - start_time
        avg_time = total_elapsed / i
        eta = avg_time * (total_frames - i)

        print(f"‚úÖ Frame {i}/{total_frames} - {frame_elapsed:.2f}s - ETA: {eta:.1f}s")

    total_time = time.time() - start_time
    print(f"üéâ Ho√†n th√†nh upscale t·∫•t c·∫£ frames trong {total_time:.2f} gi√¢y")
    return True

def create_video_from_frames(frames_dir: str, output_video_path: str, fps: float, original_video_path: str = None):
    """Gh√©p c√°c frame th√†nh video v√† copy audio t·ª´ video g·ªëc"""

    cmd = [
        'ffmpeg',
        '-framerate', str(fps),
        '-i', os.path.join(frames_dir, 'frame_%06d.png'),
        '-c:v', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-crf', '18',
        '-preset', 'medium',
        output_video_path + '_no_audio.mp4',
        '-y'
    ]

    print(f"üé¨ ƒêang t·∫°o video t·ª´ frames...")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print(f"‚ùå L·ªói khi t·∫°o video: {result.stderr}")
        return False

    if original_video_path and os.path.exists(original_video_path):
        print(f"üîä ƒêang copy audio t·ª´ video g·ªëc...")
        cmd_audio = [
            'ffmpeg',
            '-i', output_video_path + '_no_audio.mp4',
            '-i', original_video_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            output_video_path,
            '-y'
        ]

        result = subprocess.run(cmd_audio, capture_output=True, text=True)

        if result.returncode == 0:
            os.remove(output_video_path + '_no_audio.mp4')
            print(f"‚úÖ ƒê√£ th√™m audio v√†o video")
        else:
            shutil.move(output_video_path + '_no_audio.mp4', output_video_path)
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ copy audio, video ch·ªâ c√≥ h√¨nh ·∫£nh")
    else:
        shutil.move(output_video_path + '_no_audio.mp4', output_video_path)

    print(f"‚úÖ Video ƒë√£ ƒë∆∞·ª£c t·∫°o: {output_video_path}")
    return True

def upscale_video_enhanced(video_path: str, output_path: str = None, scale: int = 2,
                          model_type: str = "realesr-general", blend_ratio: float = 0.0,
                          sharpen: bool = False, keep_temp_files: bool = False):
    """Upscale to√†n b·ªô video v·ªõi c√°c t√πy ch·ªçn c·∫£i ti·∫øn"""

    if not os.path.exists(video_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file video: {video_path}")
        return

    if output_path is None:
        video_dir = os.path.dirname(video_path)
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        suffix = f"_{model_type}" if model_type != "realesr-general" else ""
        output_path = os.path.join(video_dir, f"{video_name}_upscaled_x{scale}{suffix}.mp4")

    temp_dir = "temp_video_processing"
    frames_dir = os.path.join(temp_dir, "original_frames")
    upscaled_frames_dir = os.path.join(temp_dir, "upscaled_frames")

    try:
        print(f"üìπ ƒêang ph√¢n t√≠ch video: {os.path.basename(video_path)}")
        video_info = get_video_info(video_path)
        print(f"üìä Th√¥ng tin video:")
        print(f"   - ƒê·ªô ph√¢n gi·∫£i: {video_info['width']}x{video_info['height']}")
        print(f"   - FPS: {video_info['fps']:.2f}")
        print(f"   - S·ªë frame: {video_info['frame_count']}")
        print(f"   - Th·ªùi l∆∞·ª£ng: {video_info['duration']:.2f} gi√¢y")
        print(f"   - ƒê·ªô ph√¢n gi·∫£i sau upscale: {video_info['width']*scale}x{video_info['height']*scale}")

        if not extract_frames(video_path, frames_dir):
            return

        if not upscale_frames_enhanced(frames_dir, upscaled_frames_dir, scale,
                                      model_type, blend_ratio, sharpen):
            return

        if not create_video_from_frames(upscaled_frames_dir, output_path, video_info['fps'], video_path):
            return

        print(f"\nüéâ HO√ÄN TH√ÄNH!")
        print(f"üìÅ Video g·ªëc: {video_path}")
        print(f"üíæ Video ƒë√£ upscale: {output_path}")
        print(f"üìè Scale: x{scale}")
        print(f"üé® Model: {model_type}")

    except Exception as e:
        print(f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")

    finally:
        if not keep_temp_files and os.path.exists(temp_dir):
            print(f"üßπ ƒêang d·ªçn d·∫πp files t·∫°m...")
            shutil.rmtree(temp_dir)
            print(f"‚úÖ ƒê√£ x√≥a files t·∫°m")

if __name__ == '__main__':
    print("=" * 60)
    print("üé• REALESRGAN VIDEO UPSCALER - ENHANCED VERSION")
    print("=" * 60)

    video_path = input("üìÅ Nh·∫≠p ƒë∆∞·ªùng d·∫´n video (ho·∫∑c Enter ƒë·ªÉ d√πng m·∫∑c ƒë·ªãnh): ").strip()

    if not video_path:
        video_path = "/content/drive/MyDrive/20 6 upscale video/single_long_mediumvram_8step.mp4"

    if not os.path.exists(video_path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {video_path}")
        print("B·∫°n c√≥ mu·ªën upscale ·∫£nh thay th·∫ø kh√¥ng? (y/n)")
        choice = input().strip().lower()
        if choice == 'y':
            image_path = "/content/drive/MyDrive/20 6 upscale video/blurimg.png"

            # T√πy ch·ªçn cho ·∫£nh
            print("\nüé® Ch·ªçn model:")
            print("1. realesr-general (t·ª± nhi√™n h∆°n, √≠t ho·∫°t h√¨nh)")
            print("2. RealESRGAN (s·∫Øc n√©t h∆°n, c√≥ th·ªÉ ho·∫°t h√¨nh)")
            model_choice = input("L·ª±a ch·ªçn (1/2) [m·∫∑c ƒë·ªãnh: 1]: ").strip()
            model_type = "realesr-general" if model_choice != "2" else "realesrgan"

            blend_input = input("üîÄ Blend ratio (0.0-0.5, c√†ng cao c√†ng t·ª± nhi√™n) [m·∫∑c ƒë·ªãnh: 0.1]: ").strip()
            blend_ratio = 0.1
            try:
                if blend_input:
                    blend_ratio = max(0.0, min(0.5, float(blend_input)))
            except:
                pass

            sharpen_choice = input("‚ú® √Åp d·ª•ng sharpening? (y/n) [m·∫∑c ƒë·ªãnh: n]: ").strip().lower()
            sharpen = sharpen_choice == 'y'

            upscale_image_enhanced(image_path, model_type=model_type,
                                 blend_ratio=blend_ratio, sharpen=sharpen)
    else:
        scale_input = input("üìè Nh·∫≠p scale factor (2, 4, 8) [m·∫∑c ƒë·ªãnh: 4]: ").strip()
        scale = 4
        if scale_input in ['2', '4', '8']:
            scale = int(scale_input)

        print("\nüé® Ch·ªçn model:")
        print("1. realesr-general (t·ª± nhi√™n h∆°n, √≠t b·ªã ho·∫°t h√¨nh h√≥a)")
        print("2. RealESRGAN (s·∫Øc n√©t h∆°n, c√≥ th·ªÉ b·ªã ho·∫°t h√¨nh h√≥a)")
        model_choice = input("L·ª±a ch·ªçn (1/2) [m·∫∑c ƒë·ªãnh: 1]: ").strip()
        model_type = "realesr-general" if model_choice != "2" else "realesrgan"

        blend_input = input("üîÄ Blend ratio (0.0-0.5, c√†ng cao c√†ng t·ª± nhi√™n) [m·∫∑c ƒë·ªãnh: 0.1]: ").strip()
        blend_ratio = 0.1
        try:
            if blend_input:
                blend_ratio = max(0.0, min(0.5, float(blend_input)))
        except ValueError:
            pass

        sharpen_choice = input("‚ú® √Åp d·ª•ng sharpening? (y/n) [m·∫∑c ƒë·ªãnh: n]: ").strip().lower()
        sharpen = sharpen_choice == 'y'

        print(f"\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω v·ªõi c√°c tham s·ªë:")
        print(f"   - Model: {model_type}")
        print(f"   - Scale: x{scale}")
        print(f"   - Blend ratio: {blend_ratio}")
        print(f"   - Sharpening: {'C√≥' if sharpen else 'Kh√¥ng'}")

        upscale_video_enhanced(video_path, scale=scale, model_type=model_type,
                              blend_ratio=blend_ratio, sharpen=sharpen)